
<!DOCTYPE html>
<html lang="en">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Yet another blog">
    <title>Tag: Tutorial - Yet another blog</title>
    <meta name="author" content="Khurram Amin">
    
    
    
        <link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml">
    
    <meta property="og:type" content="blog">
<meta property="og:title" content="Yet another blog">
<meta property="og:url" content="http://mkhurram.com/tags/Tutorial/index.html">
<meta property="og:site_name" content="Yet another blog">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Yet another blog">
<meta name="twitter:creator" content="@m_khurram_amin">
    
    
        
    
    
        <meta property="og:image" content="https://www.gravatar.com/avatar/09f888ccd3dee08575bfc32e8ed8f220?s=640"/>
    
    
    
    
    <!--STYLES-->
    <link rel="stylesheet" href="/assets/css/style-nuvue6sithwirecbhvw3dkaobiojqvtadsnhguwi7k04xklybw5djl1smadp.min.css">
    <!--STYLES END-->
    
    <script type="text/javascript">
        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-81742065-1']);
        _gaq.push(['_trackPageview']);
        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
    

<header id="header" data-behavior="1">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <h1 class="header-title">
        <a class="header-title-link" href="/ ">Yet another blog</a>
    </h1>
    
        
            <a  class="header-right-picture "
                href="#about">
        
        
            <img class="header-picture" src="https://www.gravatar.com/avatar/09f888ccd3dee08575bfc32e8ed8f220?s=90"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->


    

<nav id="sidebar" data-behavior="1">
    
        <div class="sidebar-profile">
            <a href="/#about">
                    <img class="sidebar-profile-picture" src="https://www.gravatar.com/avatar/09f888ccd3dee08575bfc32e8ed8f220?s=110"/>
            </a>
            <span class="sidebar-profile-name">Khurram Amin</span>
        </div>
    
    
        <ul class="sidebar-buttons">
        
            <li class="sidebar-button">
                
                    <a  class="sidebar-button-link "
                         href="/ "
                        
                    >
                
                    <i class="sidebar-button-icon fa fa-lg fa-home"></i>
                    <span class="sidebar-button-desc">Home</span>
                </a>
        </li>
        
            <li class="sidebar-button">
                
                    <a  class="sidebar-button-link "
                         href="#about"
                        
                    >
                
                    <i class="sidebar-button-icon fa fa-lg fa-question"></i>
                    <span class="sidebar-button-desc">About</span>
                </a>
        </li>
        
    </ul>
    
        <ul class="sidebar-buttons">
        
            <li class="sidebar-button">
                
                    <a  class="sidebar-button-link " href="https://twitter.com/m_khurram_amin" target="_blank">
                
                    <i class="sidebar-button-icon fa fa-lg fa-twitter"></i>
                    <span class="sidebar-button-desc">Twitter</span>
                </a>
        </li>
        
            <li class="sidebar-button">
                
                    <a  class="sidebar-button-link " href="mailto:khurram@mkhurram.com" target="_blank">
                
                    <i class="sidebar-button-icon fa fa-lg fa-envelope-o"></i>
                    <span class="sidebar-button-desc">Mail</span>
                </a>
        </li>
        
    </ul>
    
        <ul class="sidebar-buttons">
        
            <li class="sidebar-button">
                
                    <a  class="sidebar-button-link "
                         href="/atom.xml"
                        
                    >
                
                    <i class="sidebar-button-icon fa fa-lg fa-rss"></i>
                    <span class="sidebar-button-desc">RSS</span>
                </a>
        </li>
        
    </ul>
    
</nav>

            
            <div id="main" data-behavior="1"
                 class="
                        hasCoverMetaIn
                        ">
                
    

<section class="postShorten-group main-content-wrap">
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2016/09/03/an-introduction-to-convolutional-layer/">
                            Convolutional Layer in CNN
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2016-09-03T00:29:25-04:00">
	
		    Sep 03, 2016
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <h1 id="table-of-contents">Table of Contents</h1><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#convolutional-layer"><span class="toc-text">Convolutional Layer</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#min-summary"><span class="toc-text">2-min Summary</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#parameters-of-cl"><span class="toc-text">Parameters of CL</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#indepth-review"><span class="toc-text">Indepth Review</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#what-is-a-convolutional-layer"><span class="toc-text">What is a Convolutional Layer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#how-to-convolutional-layer-removes-some-of-above-mentioned-drawbacks"><span class="toc-text">How to convolutional layer removes some of above mentioned drawbacks?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#code-examples"><span class="toc-text">Code examples</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#references"><span class="toc-text">References</span></a></li></ol></li></ol></li></ol>

<h1 id="convolutional-layer">Convolutional Layer</h1>
<p>A very informative tutorial on Convolutional Neural Networks by <a href="http://cs.stanford.edu/people/karpathy/" target="_blank" rel="external">Andrej Karpath</a> can be found here <a href="https://www.youtube.com/watch?v=V8JDMkARdfU&amp;index=7&amp;list=PLlJy-eBtNFt6EuMxFYRiNRS07MCWN5UIA]" target="_blank" rel="external">Video</a>, <a href="http://cs231n.github.io/convolutional-networks/" target="_blank" rel="external">Lecture Notes</a>, <a href="http://cs231n.stanford.edu/slides/winter1516_lecture7.pdf" target="_blank" rel="external">Slides</a>. <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network" target="_blank" rel="external">Wikipedia</a> also has a very detailed article explaining the working of CNN.</p>
<h2 id="min-summary">2-min Summary</h2>
<p>The basic purpose of introducing Convolutional Layer (<strong>CL</strong>) in Neural Network (<strong>NN</strong>) architecture is: 1. To incorporate Translational Invariance 2. To exploit (spatial/temporal) local correlations</p>
<p>Added advantages of CL are: 1. Reduction in number of learnable parameters (<strong>LP</strong>) 2. Avoids duplicate nodes (Neuron(s) with similar parameters) 3. A better understanding of what network is learning</p>
<p>A convolutional layer learns an <span class="math">\(H \times W\)</span> filter which is convolved with the whole input from previous layer with stride (shift/step) <strong>S</strong> and resulting output is accumulated into a 2D matrix (plane). This output plane is called a <strong>feature map</strong>. A CL can be configured to produce <strong>N</strong> feature maps. Usually the size of convolutional kernel is kept square i.e. <span class="math">\(H \times H\)</span>.</p>
<div class="figure fig-100" style="width:;"><img class="fig-img" src="http://cs231n.github.io/assets/cnn/stride.jpeg" alt="Figure 0: 1D convolutional operation. The gray boxes are input, green box on right is the convolutional kernel. On left, kernel convolves with the input with stride 1 and produces the output in yellow. On right, same kernel convolves with the same input with stride 2 to produce out in green.  (image is taken from Stanford's CS231n lecture notes)"><span class="caption">Figure 0: 1D convolutional operation. The gray boxes are input, green box on right is the convolutional kernel. On left, kernel convolves with the input with stride 1 and produces the output in yellow. On right, same kernel convolves with the same input with stride 2 to produce out in green.  (image is taken from Stanford's CS231n lecture notes)</span></div>

<h3 id="parameters-of-cl">Parameters of CL</h3>
<p>H = size of (square) filter, How big the learned filter/mask should be?</p>
<p>S = stride (step/shift), What should be the step size during convolution operation?</p>
<p>N = number of feature maps, How many filters/masks should be learned?</p>
<p>P = Padding size, How many rows and columns should be inserted on borders of input volume/image/plane?</p>
<h2 id="indepth-review">Indepth Review</h2>
<div class="figure fig-100" style="width:;"><img class="fig-img" src="http://cs231n.github.io/assets/nn1/neural_net2.jpeg" alt="Figure 1: A fully connected neural network with 2 hidden layers. (image is taken from Stanford's CS231n lecture notes)"><span class="caption">Figure 1: A fully connected neural network with 2 hidden layers. (image is taken from Stanford's CS231n lecture notes)</span></div>



<p>A NN can be designed in fully connected fashion i.e. each neuron in each layer takes every output of previous layer as input. While such an architecture will be simple to design but it will have its drawbacks.</p>
<p>First, the number of LP in such a network will explode exponentially. For a recognition task if an <span class="math">\(H \times W\)</span> image is used as input and network is designed in FC fashion then the number of LP in first hidden layer will be <span class="math">\(H \times W \times N,\)</span> whereas N is the number of nodes in first hidden layer. For a typical patch of size <span class="math">\(100 \times 100\)</span> and a hidden layer with <span class="math">\(100\)</span> nodes, the LP in first layer will be <span class="math">\(0.1 million\)</span>. Although such huge number of parameters will increase the learning capacity of our learning machine/system but to learn such a large number of parameters will require even larger dataset. Availability of larger (gigantic) dataset cannot be ensured for every learning problem. This scenario becomes more drastic in supervised learning tasks where annotations are also required for training.</p>
<p>Second, the incorporation of prior knowledge about problem in learning machine/system can improve system accuracy. This fact can be of greater importance if training data is scarcer. In FC network either no-prior knowledge is incorporated or if one wants to incorporate prior-knowledge he has to do this in pre or post processing steps. This will either result in sub-par learning (in case of no prior-knowledge incorporation) or as a cumbersome and potentially more time consuming system. Moreover another draw back of pre/post processing is sub-optimality of such a process if designed by hand. In case of images one such prior-knowledge is correlation between spatially nearby pixels.</p>
<span class="highlight-text danger">Insert images of objects where local information is enough to take some decision about the scene/object/image & do some discussion on them.</span>

<p>Third, geometric transformations applied on input image (object) should not have any effect on the output of network. One such geometric transformation is 2D translation i.e. an object can appear, in same pose, anywhere in the input image. In FC network architecture, this phenomenon is captured by learning not only the appearance of object but also the all possible locations in the input field where the object can exist. As a result many nodes will have same/similar parameters and will respond same object appearing in different spatial locations. This will not require larger training set i.e. all combinations of transformed images (objects) must be provided to build/learn invariance to the geometric transformations in learning system.</p>
<p>Four, complex objects (structures) are made of simpler objects (shapes). A house can be made by arranging a set of 11 lines in a <em>particular</em> order. So it will be useful if our learning system has the ability to extract these elementary objects and a way to combine them to learn the ultimate shape of object. In FC network it cannot be ensured that the network will always learn this hierarchical structure.</p>
<span class="highlight-text danger">Insert a figure of a line drawing of a house here</span>

<h3 id="what-is-a-convolutional-layer">What is a Convolutional Layer</h3>
<div class="figure fig-100" style="width:;"><img class="fig-img" src="http://cs231n.github.io/assets/cnn/cnn.jpeg" alt="Figure 2: A convolutional neural network with 3 convolutional layers. (image is taken from Stanford's CS231n lecture notes)"><span class="caption">Figure 2: A convolutional neural network with 3 convolutional layers. (image is taken from Stanford's CS231n lecture notes)</span></div>



<p>In CL each neuron is connected to a spatially local, of size <span class="math">\(H_c \times W_c\)</span>, patch of previous layer. It takes dot product of <span class="math">\(H_c \times W_c\)</span> patch and a similar sized weight matrix, adds some scalar bias and outputs a scalar value. This spatially small neighborhood of size <span class="math">\(H_c \times W_c\)</span> in previous layer is called <strong>receptive field</strong> of the neuron. To get output from other locations of the input image, this node is repeated (with same weights/LP) and is fed with translated patches/windows. These repeated neurons are arranged in a 2D plane. This plane is called <strong>feature map</strong>. In a feature map every node have same parameters as other nodes.</p>
<div class="figure fig-100" style="width:;"><img class="fig-img" src="http://cs231n.github.io/assets/cnn/depthcol.jpeg" alt="Figure 3: A convolutional layer operating on an input of $32*32*3$, shown in lighter red, the convolutional mask, shown in darker red and the output feature volume shown in blue.  (image is taken from Stanford's CS231n lecture notes)"><span class="caption">Figure 3: A convolutional layer operating on an input of $32*32*3$, shown in lighter red, the convolutional mask, shown in darker red and the output feature volume shown in blue.  (image is taken from Stanford's CS231n lecture notes)</span></div>



<div class="figure fig-100" style="width:;"><img class="fig-img" src="http://cs231n.github.io/assets/nn1/neuron_model.jpeg" alt="Figure 4: Each node in a convolutional layer takes a set of feature vector $x$ as input, computes its dot product with a similar size weights vector $w$, adds a scalar bias b and outputs a scalar value $f(x,w, b)$. (image is taken from Stanford's CS231n lecture notes)"><span class="caption">Figure 4: Each node in a convolutional layer takes a set of feature vector $x$ as input, computes its dot product with a similar size weights vector $w$, adds a scalar bias b and outputs a scalar value $f(x,w, b)$. (image is taken from Stanford's CS231n lecture notes)</span></div>



<ol style="list-style-type: decimal">
<li>Number of parameters in a single node = <span class="math">\(H_c \times W_c \times N_c + 1\)</span>, whereas Nc is the number of channels in input volume and the kernel</li>
<li>Number of nodes in a feature map = $  $</li>
<li>Number of parameters and connections in a feature map (without padding the input) = <span class="math">\(\frac{H - H_c + 1}{S_h} \times \frac{W - W_c + 1}{S_w} \times H_c \times W_c \times N_c + 1 \)</span></li>
<li>Number of free/LP in a feature map = <span class="math">\(H_c \times W_c \times N_c + 1\)</span></li>
<li>In practice some kind of padding is done on the borders of input volume to avoid reducing the width and height of output volume during convolutional operation. In such a case the number of nodes and total parameters and connections change accordingly while the number of LP remain same.</li>
</ol>
<p>Another key point to note over here is that a single convolutional filter operates on the entire depth of the input volume and thus have the same depth as input volume. While the depth of output volume can be controlled by number of features parameter.</p>
<iframe src="//cs231n.github.io/assets/conv-demo/index.html" width="100%" height="680px;" style="border:none;"> </iframe>
<p>Figure 6: The above figure shows a 3 channel input of size 5x5. Each channel is stacked in a column separately on left. The 5x5 input is zero-padded with p = 1. The stride is 2. The first red column from left shows the first 3x3x3 kernel whereas each channel is stacked over one another. Similarly the second red column from red shows the second 3x3x3 convolutional filter. The green box on right shows the output of convolutional operation. (This visualization is taken from Stanford’s CS231n course notes).</p>
<div class="figure fig-100" style="width:;"><img class="fig-img" src="http://cs231n.github.io/assets/cnn/weights.jpeg" alt="Figure 7: Each block in above figure shows a feature kernel learned by the first layer of an example convolutional neural network There are 96 kernels. (image is taken from Stanford's CS231n lecture notes)"><span class="caption">Figure 7: Each block in above figure shows a feature kernel learned by the first layer of an example convolutional neural network There are 96 kernels. (image is taken from Stanford's CS231n lecture notes)</span></div>

<h3 id="how-to-convolutional-layer-removes-some-of-above-mentioned-drawbacks">How to convolutional layer removes some of above mentioned drawbacks?</h3>
<h3 id="code-examples">Code examples</h3>
<h3 id="references">References</h3>

                    
                        
                    
                    
                        <p>
                            <a href="/2016/09/03/an-introduction-to-convolutional-layer/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    <div class="pagination-bar">
    <ul class="pagination">
        
        
        <li class="pagination-number">page 1 of 1</li>
    </ul>
</div>

</section>


                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2016 Khurram Amin. All Rights Reserved.
    </span>
</footer>

            </div>
            
        </div>
        


    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-remove"></i>
        </div>
        
            <img id="about-card-picture" src="https://www.gravatar.com/avatar/09f888ccd3dee08575bfc32e8ed8f220?s=110"/>
        
            <h4 id="about-card-name">Khurram Amin</h4>
        
            <h5 id="about-card-bio"><p>I am a researcher and a wannabe entrepreneur</p>
</h5>
        
        
            <h5 id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>Computer Vision &amp; Machine Learning Researcher</p>

            </h5>
        
        
            <h5 id="about-card-location">
                <i class="fa fa-map-marker"></i>
                <br/>
                Makkah, KSA
            </h5>
        
    </div>
</div>

        
<div id="cover" style="background-image:url('https://github.com/khurram-amin/public_on_web2/raw/master/body_bg1.jpg');"></div>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
    <!--SCRIPTS-->
<script src="/assets/js/script-i4qo6jx6jji9fg0dftpya6ivemizsbow4fhow76d8dwpm7m1wbvi378ssumx.min.js"></script>
<!--SCRIPTS END-->



</html>
